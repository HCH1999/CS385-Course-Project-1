==>Arguments:
arch:resnet18
checkpoint:./checkpoints/
datapath:./data/
epochs:50
evaluate:False
gamma:0.1
gpu_id:0
lr:0.1
momentum:0.9
schedule:[20, 40]
train_batchsize:64
val_batchsize:16
weight_decay:0.0001
==>Training log:
Learning Rate	Train Loss	Valid Loss	Train Acc	Valid Acc	
0.100000	2.167975	1.558900	23.820250	46.957588	
0.100000	1.677351	1.008583	42.966541	67.025200	
0.100000	1.370651	0.830012	54.352486	72.979408	
0.100000	1.230631	0.666883	59.228470	78.703133	
0.100000	1.159996	0.766311	61.802967	74.750305	
0.100000	1.105152	0.682867	63.786396	78.119240	
0.100000	1.069058	0.566241	65.257927	82.648277	
0.100000	1.053664	0.550492	65.582809	82.709740	
0.100000	1.028418	0.545418	66.418228	83.151505	
0.100000	1.021234	0.578569	66.769043	81.503532	
0.100000	1.002269	0.509988	67.256371	83.912109	
0.100000	0.989010	0.529244	67.940262	83.739243	
0.100000	0.974575	0.540964	68.396194	82.963272	
0.100000	0.972414	0.534726	68.490379	83.197601	
0.100000	0.964367	0.492200	68.626884	84.764900	
0.100000	0.954246	0.508385	69.182465	84.365395	
0.100000	0.954204	0.529064	69.231606	83.608635	
0.100000	0.941969	0.514885	69.533287	84.219421	
0.100000	0.940780	0.508795	69.589256	83.854485	
0.100000	0.939378	0.508384	69.694359	84.177162	
0.010000	0.819616	0.352194	73.618904	89.401505	
0.010000	0.782078	0.335871	75.050850	89.862473	
0.010000	0.769296	0.331407	75.325226	90.031494	
0.010000	0.754114	0.319181	75.740204	90.427162	
0.010000	0.751146	0.323285	76.039146	90.185158	
0.010000	0.738934	0.314595	76.485519	90.473259	
0.010000	0.733391	0.310794	76.426826	90.615395	
0.010000	0.731406	0.298720	76.478699	91.099411	
0.010000	0.728484	0.296334	76.747612	91.014900	
0.010000	0.728368	0.290315	76.660248	91.256912	
0.010000	0.719481	0.287974	76.886848	91.314537	
0.010000	0.714937	0.303462	77.146210	90.734482	
0.010000	0.718780	0.294719	77.071129	91.153191	
0.010000	0.721399	0.279750	76.869102	91.698677	
0.010000	0.711520	0.293911	77.260872	91.183929	
0.010000	0.710856	0.299324	77.236305	90.999535	
0.010000	0.707744	0.298534	77.224014	91.053314	
0.010000	0.708261	0.275849	77.365982	91.894592	
0.010000	0.704005	0.296792	77.413757	91.095573	
0.010000	0.702345	0.290366	77.468361	91.383682	
0.001000	0.683578	0.272817	78.103111	91.848495	
0.001000	0.678080	0.279033	78.227333	91.667946	
0.001000	0.681263	0.279821	78.124954	91.518127	
0.001000	0.669227	0.272184	78.759705	91.875381	
0.001000	0.663945	0.269924	78.706467	91.959892	
0.001000	0.669980	0.269977	78.534470	91.944527	
0.001000	0.662601	0.265639	78.823868	92.090500	
0.001000	0.661339	0.269238	78.889389	91.886909	
0.001000	0.669504	0.263466	78.658691	92.128914	
0.001000	0.666059	0.262546	78.698280	92.201904	
