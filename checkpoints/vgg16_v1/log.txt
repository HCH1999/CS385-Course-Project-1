==>Arguments:
arch:vgg16_v1
checkpoint:./checkpoints/
datapath:./data/
epochs:50
evaluate:False
gamma:0.1
gpu_id:0
lr:0.1
momentum:0.9
schedule:[20, 40]
train_batchsize:64
val_batchsize:16
weight_decay:0.0001
==>Training log:
Learning Rate	Train Loss	Valid Loss	Train Acc	Valid Acc	
0.010000	1.948550	1.529459	31.975101	49.496773	
0.010000	1.260950	0.645810	58.883110	79.832512	
0.010000	1.049739	0.549733	65.906326	82.740471	
0.010000	0.948986	0.462293	69.631569	85.909645	
0.010000	0.896491	0.382956	71.447098	88.671631	
0.010000	0.857177	0.357101	72.642883	89.220955	
0.010000	0.826457	0.321734	73.800453	90.450211	
0.010000	0.805749	0.294230	74.409271	91.783188	
0.010000	0.780850	0.341720	75.278809	89.589737	
0.010000	0.769845	0.297032	75.665123	91.456665	
0.010000	0.749321	0.306476	76.294411	90.911186	
0.010000	0.738794	0.254283	76.718948	92.501534	
0.010000	0.727841	0.271065	77.006973	92.059769	
0.010000	0.714784	0.268136	77.445160	92.105865	
0.010000	0.709811	0.268619	77.598045	92.067451	
0.010000	0.698699	0.253929	77.902451	92.570679	
0.010000	0.689024	0.252254	78.200035	92.605255	
0.010000	0.681631	0.239316	78.526283	93.027809	
0.010000	0.681625	0.233593	78.541298	93.066223	
0.010000	0.666498	0.234495	78.972656	93.231407	
0.010000	0.662204	0.271803	79.095512	91.933006	
0.010000	0.659995	0.239365	79.282524	93.012444	
0.010000	0.649455	0.228567	79.499565	93.438843	
0.010000	0.650739	0.230712	79.354874	93.269821	
0.010000	0.645432	0.231882	79.539154	93.369698	
0.010000	0.641392	0.234043	79.675659	93.162262	
0.010000	0.631432	0.212008	80.060608	93.853714	
0.010000	0.627246	0.218284	80.221680	93.623230	
0.010000	0.617924	0.197577	80.467392	94.422249	
0.010000	0.624606	0.213511	80.209396	93.842194	
0.010000	0.622599	0.224495	80.190285	93.496468	
0.010000	0.616170	0.206234	80.300858	94.045792	
0.010000	0.613825	0.195266	80.586151	94.353104	
0.010000	0.602944	0.206910	80.975197	93.892128	
0.010000	0.602646	0.222493	80.672150	93.546402	
0.010000	0.606185	0.200622	80.855072	94.268593	
0.010000	0.599321	0.212632	80.886467	93.911339	
0.010000	0.599306	0.199288	81.051636	94.406883	
0.010000	0.594521	0.196357	81.144463	94.376152	
0.010000	0.590677	0.194195	81.134903	94.464500	
0.010000	0.586648	0.220444	81.384712	93.750000	
0.010000	0.586505	0.207456	81.407921	94.253227	
0.010000	0.578994	0.190941	81.596298	94.552856	
0.010000	0.579131	0.196354	81.567627	94.406883	
0.010000	0.575251	0.197233	81.787407	94.406883	
0.010000	0.569361	0.186831	81.893875	94.710358	
0.010000	0.570883	0.183334	81.917084	94.748772	
0.010000	0.566716	0.180921	82.064514	94.890900	
0.010000	0.567301	0.199134	81.889786	94.372307	
0.010000	0.564736	0.190915	81.908897	94.625847	
