==>Arguments:
arch:vgg19
checkpoint:./checkpoints/
datapath:./data/
epochs:50
evaluate:False
gamma:0.1
gpu_id:1
lr:0.1
momentum:0.9
schedule:[20, 40]
train_batchsize:64
val_batchsize:16
weight_decay:0.0001
==>Training log:
Learning Rate	Train Loss	Valid Loss	Train Acc	Valid Acc	
0.010000	2.109123	1.664885	24.939596	41.487400	
0.010000	1.597957	1.083666	45.696655	64.605103	
0.010000	1.167585	0.639981	62.320324	80.450981	
0.010000	1.034815	0.520004	66.973801	84.519051	
0.010000	0.948726	0.415211	70.000137	87.684387	
0.010000	0.903938	0.361301	71.512619	89.443756	
0.010000	0.873592	0.400649	72.399902	88.252914	
0.010000	0.840923	0.376708	73.726738	88.821449	
0.010000	0.816126	0.361047	74.457047	89.090347	
0.010000	0.790786	0.346212	75.229668	89.551323	
0.010000	0.780130	0.308764	75.423508	91.364471	
0.010000	0.764981	0.296857	76.070541	91.548859	
0.010000	0.746457	0.285671	76.609741	91.333740	
0.010000	0.745202	0.277471	76.527840	91.952209	
0.010000	0.734755	0.255924	77.198082	92.539948	
0.010000	0.719229	0.274531	77.436966	92.178856	
0.010000	0.710656	0.275975	77.740013	91.798553	
0.010000	0.705001	0.273136	77.924294	91.948372	
0.010000	0.696451	0.263686	78.272385	92.543793	
0.010000	0.689326	0.239399	78.448471	93.269821	
0.010000	0.686710	0.234926	78.576790	93.365852	
0.010000	0.674685	0.230920	78.804756	93.481102	
0.010000	0.667920	0.209365	79.275696	94.095726	
0.010000	0.663168	0.231862	79.238846	93.281342	
0.010000	0.656983	0.242748	79.338493	93.131531	
0.010000	0.651108	0.243773	79.604675	93.120003	
0.010000	0.648722	0.214261	79.701599	93.895973	
0.010000	0.641377	0.231041	79.895432	93.473419	
0.010000	0.643287	0.211889	79.881783	94.145668	
0.010000	0.630639	0.215891	80.225777	93.773048	
0.010000	0.630684	0.233639	80.351364	93.369698	
0.010000	0.629085	0.225112	80.343170	93.665489	
0.010000	0.629757	0.211017	80.311775	93.949753	
0.010000	0.617220	0.208660	80.702187	93.945908	
0.010000	0.613548	0.210970	80.835960	94.034264	
0.010000	0.617448	0.207723	80.665329	94.191765	
0.010000	0.614742	0.205674	80.919228	94.210968	
0.010000	0.610118	0.230308	80.956085	93.434998	
0.010000	0.606325	0.196056	81.029800	94.529808	
0.010000	0.603852	0.200468	81.100777	94.356941	
0.010000	0.601261	0.194688	81.272774	94.541328	
0.010000	0.591093	0.197448	81.586739	94.525963	
0.010000	0.595271	0.201586	81.371063	94.525963	
0.010000	0.585704	0.214103	81.667282	94.034264	
0.010000	0.589912	0.191454	81.375160	94.595108	
0.010000	0.586168	0.209227	81.579918	94.264748	
0.010000	0.579615	0.186366	81.691849	94.802551	
0.010000	0.574620	0.214150	82.124573	93.888290	
0.010000	0.572865	0.204368	81.983971	94.383835	
0.010000	0.577442	0.189677	81.974419	94.783340	
