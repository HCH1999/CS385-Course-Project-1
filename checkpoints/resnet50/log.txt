==>Arguments:
arch:resnet50
checkpoint:./checkpoints/
datapath:./data/
epochs:50
evaluate:False
gamma:0.1
gpu_id:0
lr:0.1
momentum:0.9
schedule:[20, 40]
train_batchsize:64
val_batchsize:16
weight_decay:0.0001
==>Training log:
Learning Rate	Train Loss	Valid Loss	Train Acc	Valid Acc	
0.100000	2.455109	2.226860	18.529287	19.572065	
0.100000	2.237654	2.214450	18.916964	19.625845	
0.100000	2.224036	2.195896	20.069071	21.565765	
0.100000	2.194480	2.175468	21.880503	23.582514	
0.100000	2.164338	2.125741	23.801138	25.868162	
0.100000	2.142143	2.108474	24.601061	27.765825	
0.100000	2.092998	2.086552	26.715534	26.317608	
0.100000	2.066568	1.950974	28.243034	33.059311	
0.100000	1.983199	1.703241	31.633837	43.181469	
0.100000	1.901707	1.708775	34.572803	43.058544	
0.100000	1.872021	1.580421	35.981544	46.173939	
0.100000	1.787481	1.358033	39.129364	55.673786	
0.100000	1.756993	1.501720	40.135414	50.656883	
0.100000	1.655587	1.361663	44.124111	55.320374	
0.100000	1.565776	1.117577	47.472595	63.494926	
0.100000	1.479164	0.919301	50.912540	70.547783	
0.100000	1.411813	0.900339	53.144409	71.177780	
0.100000	1.353272	0.918381	55.392658	71.097107	
0.100000	1.313285	0.843267	56.566608	72.545326	
0.100000	1.269361	0.765976	58.301594	76.386757	
0.010000	1.112977	0.579893	63.281322	82.006760	
0.010000	1.065929	0.551020	65.167831	82.963272	
0.010000	1.050215	0.544880	65.604652	82.947906	
0.010000	1.033580	0.546276	66.192993	82.890289	
0.010000	1.022996	0.534542	66.397751	83.128456	
0.010000	1.009921	0.532637	66.875519	83.159187	
0.010000	0.998776	0.509009	67.317795	84.004303	
0.010000	1.000814	0.524235	67.371033	83.681618	
0.010000	0.985754	0.509710	67.710938	83.866013	
0.010000	0.975897	0.511465	68.037186	83.892899	
0.010000	0.973128	0.486926	68.218735	84.626610	
0.010000	0.967486	0.487890	68.411209	84.703438	
0.010000	0.967625	0.496185	68.568192	84.780266	
0.010000	0.965225	0.484110	68.498573	84.749535	
0.010000	0.957074	0.501472	68.944946	84.411491	
0.010000	0.944527	0.491762	69.186562	84.568993	
0.010000	0.940579	0.469913	69.443192	85.229713	
0.010000	0.935280	0.461869	69.653412	85.898125	
0.010000	0.936353	0.467426	69.463669	85.452515	
0.010000	0.926045	0.449443	69.942802	85.940376	
0.001000	0.897550	0.419835	71.004814	86.781654	
0.001000	0.889618	0.425151	71.101738	86.639519	
0.001000	0.888922	0.424899	71.120850	86.797020	
0.001000	0.876743	0.425669	71.666870	86.770126	
0.001000	0.877627	0.423163	71.500336	86.693298	
0.001000	0.872736	0.418571	71.666870	86.977562	
0.001000	0.871531	0.426556	71.761055	86.750923	
0.001000	0.873281	0.418169	71.830673	86.989090	
0.001000	0.859926	0.417020	72.204704	86.916100	
0.001000	0.867138	0.418660	71.889374	86.973724	
