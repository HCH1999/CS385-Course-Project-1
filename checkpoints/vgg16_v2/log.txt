==>Arguments:
arch:vgg16_v2
checkpoint:./checkpoints/
datapath:./data/
epochs:50
evaluate:False
gamma:0.1
gpu_id:1
lr:0.1
momentum:0.9
schedule:[20, 40]
train_batchsize:64
val_batchsize:16
weight_decay:0.0001
==>Training log:
Learning Rate	Train Loss	Valid Loss	Train Acc	Valid Acc	
0.010000	2.434077	2.467646	17.475462	18.842194	
0.010000	2.066339	1.650160	27.223337	44.675781	
0.010000	1.666964	0.930168	43.026604	69.748772	
0.010000	1.255435	0.716362	58.604637	76.724800	
0.010000	1.087401	0.513806	64.651840	83.562538	
0.010000	1.002356	0.480639	67.533478	84.492165	
0.010000	0.941370	0.402569	69.845886	87.765060	
0.010000	0.899428	0.395144	71.275101	88.199135	
0.010000	0.876730	0.345083	71.956261	89.355408	
0.010000	0.848599	0.340317	73.018280	89.789490	
0.010000	0.830436	0.321081	73.661217	90.404114	
0.010000	0.812898	0.337010	74.042068	89.766441	
0.010000	0.799242	0.326118	74.499367	89.962349	
0.010000	0.774731	0.278899	75.418045	91.687149	
0.010000	0.767835	0.297114	75.686966	91.080208	
0.010000	0.754350	0.272757	76.182480	91.829285	
0.010000	0.750526	0.272800	76.342194	91.883064	
0.010000	0.743447	0.272979	76.459587	91.921478	
0.010000	0.728189	0.255575	76.937355	92.336357	
0.010000	0.724201	0.261990	77.146210	92.217270	
0.010000	0.727815	0.254882	77.139381	92.359406	
0.010000	0.710082	0.255802	77.689499	92.551476	
0.010000	0.696220	0.245922	78.078545	92.774277	
0.010000	0.689214	0.254489	78.123589	92.409340	
0.010000	0.685419	0.239674	78.344727	92.885674	
0.010000	0.687100	0.243416	78.240982	92.785797	
0.010000	0.679957	0.220681	78.560410	93.523354	
0.010000	0.673069	0.223874	78.791107	93.365852	
0.010000	0.675124	0.230843	78.811577	93.319756	
0.010000	0.663214	0.231684	78.978119	93.312073	
0.010000	0.663805	0.251562	79.035446	92.332512	
0.010000	0.657145	0.224625	79.334396	93.550247	
0.010000	0.652302	0.230664	79.234749	93.289024	
0.010000	0.648385	0.205567	79.528236	93.892128	
0.010000	0.644555	0.225333	79.646996	93.377380	
0.010000	0.643469	0.227334	79.764389	93.250610	
0.010000	0.640730	0.215685	79.623787	93.657806	
0.010000	0.638265	0.228458	79.806709	93.377380	
0.010000	0.632392	0.234052	79.965050	93.077751	
0.010000	0.635008	0.231376	79.881783	93.408112	
0.010000	0.633303	0.210853	80.061974	94.018898	
0.010000	0.632131	0.226613	80.034668	93.515671	
0.010000	0.617752	0.199980	80.474220	94.184082	
0.010000	0.612446	0.208969	80.631203	93.972801	
0.010000	0.618760	0.210930	80.411423	93.907494	
0.010000	0.618262	0.201664	80.546570	94.157188	
0.010000	0.607066	0.198012	80.721291	94.257065	
0.010000	0.604803	0.202169	80.845512	94.276276	
0.010000	0.602447	0.215238	80.890564	93.895973	
0.010000	0.596240	0.208077	81.220909	94.080360	
